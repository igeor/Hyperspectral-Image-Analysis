{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "\n",
    "from __init__ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5toNumpy(filepath):\n",
    "    f = h5py.File(filepath, 'r')\n",
    "    image = np.array(f['dataset'])\n",
    "    energies = np.array(f['energies'])\n",
    "    f.close()\n",
    "    return image\n",
    "\n",
    "toTensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "inTrainImage = h5toNumpy(parentdir + \"\\\\\" + \"data\\\\panagia.h5\").astype(np.float32)\n",
    "inTrainImage = torch.from_numpy(inTrainImage)\n",
    "inTrainImage = torch.reshape(inTrainImage, [21, 33, 2048])\n",
    "inTrainImage = torch.swapaxes(inTrainImage,0,2);\tinTrainImage = np.swapaxes(inTrainImage,1,2)\n",
    "inTrainImage = torch.rot90(inTrainImage, 2, (2,1))\n",
    "\n",
    "outTrainImage = toTensor(Image.open(parentdir + \"\\\\\" + \"data\\panagia.png\").convert('RGB'))\n",
    "\n",
    "inTestImage = h5toNumpy(parentdir + \"\\\\\" + \"data\\\\jesus.h5\").astype(np.float32)\n",
    "inTestImage = torch.from_numpy(inTestImage)\n",
    "inTestImage = torch.reshape(inTestImage, [31, 46, 2048])\n",
    "inTestImage = torch.swapaxes(inTestImage,0,2);\tinTestImage = np.swapaxes(inTestImage,1,2)\n",
    "inTestImage = torch.rot90(inTestImage, 2, (2,1))\n",
    "\n",
    "outTestImage = toTensor(Image.open(parentdir + \"\\\\\" + \"data\\jesus.png\").convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(nrows=1, ncols=4, figsize=(30,10))\n",
    "\n",
    "ax[0].imshow(inTrainImage.sum(axis=0))\n",
    "ax[1].imshow(outTrainImage.permute(1, 2, 0))\n",
    "ax[2].imshow(inTestImage.sum(axis=0))\n",
    "ax[3].imshow(outTestImage.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,inputImage,targetImage, specRange=[60,900]):\n",
    "        self.specRange = specRange\n",
    "        self.inputImage = inputImage\n",
    "        self.targetImage = targetImage\n",
    "       \n",
    "        self.inputImage = torch.flatten(self.inputImage, start_dim=1, end_dim=-1)\n",
    "        self.targetImage = torch.flatten(self.targetImage, start_dim=1, end_dim=-1)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        return (self.inputImage[self.specRange[0]:self.specRange[1],index], self.targetImage[:,index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.inputImage.shape[-1]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancelOut(nn.Module):\n",
    "    def __init__(self,inp, *input, **kwargs):\n",
    "        super(CancelOut, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.zeros(inp))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return (x * torch.sigmoid(self.weights.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, cancel_out_layer):\n",
    "        super(cEncoder, self).__init__()\n",
    "        self.cancel_out_layer = cancel_out_layer\n",
    "        self.l1 =  nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l2 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//2, in_channels//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l3 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//4, in_channels//8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l4 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//8, in_channels//16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l5 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//16, in_channels//32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l6 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//32, out_channels),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn. init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu')) \n",
    "    def forward(self, x_in, train=True):\n",
    "        x1 = self.cancel_out_layer(x_in)\n",
    "        x1 = self.l1(x_in) #print(x1.shape)\n",
    "        x2 = self.l2(x1); \n",
    "        if(train): x2 == self.dropout(x2) #print(x2.shape)\n",
    "        x3 = self.l3(x2); \n",
    "        if(train): x3 == self.dropout(x3) #print(x3.shape)\n",
    "        x4 = self.l4(x3)\n",
    "        if(train): x4 == self.dropout(x4)\n",
    "        x5 = self.l5(x4) #print(x4.shape)\n",
    "        if(train): x5 == self.dropout(x5) #print(x4.shape)\n",
    "        x_enc = self.l6(x5)\n",
    "        return x1,x2,x3,x4,x5,x_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.l1 =  nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l2 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//2, in_channels//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l3 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//4, in_channels//8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l4 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//8, in_channels//16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l5 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//16, in_channels//32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l6 =  nn.Sequential(\n",
    "            nn.Linear(in_channels//32, out_channels),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn. init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu')) \n",
    "                \n",
    "    def forward(self, x_in, train=True):\n",
    "        x1 = self.l1(x_in) #print(x1.shape)\n",
    "        x2 = self.l2(x1); \n",
    "        if(train): x2 == self.dropout(x2) #print(x2.shape)\n",
    "        x3 = self.l3(x2); \n",
    "        if(train): x3 == self.dropout(x3) #print(x3.shape)\n",
    "        x4 = self.l4(x3)\n",
    "        if(train): x4 == self.dropout(x4)\n",
    "        x5 = self.l5(x4) #print(x4.shape)\n",
    "        if(train): x5 == self.dropout(x5) #print(x4.shape)\n",
    "        x_enc = self.l6(x5)\n",
    "        return x1,x2,x3,x4,x5,x_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(uDecoder, self).__init__()\n",
    "        self.l1 =  nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels//32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l2 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//32, out_channels//16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l3 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//16, out_channels//8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l4 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//8, out_channels//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l5 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//4, out_channels//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l6 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//2, out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lfin = nn.Linear(out_channels, out_channels)\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn. init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu')) \n",
    "    def forward(self, x1_e,x2_e,x3_e,x4_e,x5_e,x_in, train=True):\n",
    "        x1 = self.l1(x_in) #print(x1.shape, x5_e.shape)\n",
    "        x2 = self.l2(x1 * x5_e); \n",
    "        if(train): x2 == self.dropout(x2) #print(x2.shape)    \n",
    "        x3 = self.l3(x2 * x4_e); \n",
    "        if(train): x3 == self.dropout(x3) #print(x3.shape)\n",
    "        x4 = self.l4(x3 * x3_e); \n",
    "        if(train): x4 == self.dropout(x4) #print(x4.shape)\n",
    "        x5 = self.l5(x4 * x2_e); \n",
    "        if(train): x5 == self.dropout(x5) #print(x5.shape)\n",
    "        x_6 = self.l6(x5 * x1_e) #print(x5.shape)\n",
    "        x_dec = self.lfin(x_6)\n",
    "        return x_dec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.l1 =  nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels//32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l2 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//32, out_channels//16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l3 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//16, out_channels//8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l4 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//8, out_channels//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l5 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//4, out_channels//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l6 =  nn.Sequential(\n",
    "            nn.Linear(out_channels//2, out_channels),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn. init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu')) \n",
    "    def forward(self, x1_e,x2_e,x3_e,x4_e,x5_e,x_in, train=True):\n",
    "        x1 = self.l1(x_in) #print(x1.shape, x5_e.shape)\n",
    "        x2 = self.l2(x1 + x5_e); \n",
    "        if(train): x2 == self.dropout(x2) #print(x2.shape)    \n",
    "        x3 = self.l3(x2 + x4_e); \n",
    "        if(train): x3 == self.dropout(x3) #print(x3.shape)\n",
    "        x4 = self.l4(x3 + x3_e); \n",
    "        if(train): x4 == self.dropout(x4) #print(x4.shape)\n",
    "        x5 = self.l5(x4 + x2_e); \n",
    "        if(train): x5 == self.dropout(x5) #print(x5.shape)\n",
    "        x_dec = self.l6(x5)\n",
    "        return x_dec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(img1, img2):\n",
    "    return 20 * torch.log10(\n",
    "        1.0 / torch.sqrt(\n",
    "            torch.mean((img1*1.0 - img2*1.0) ** 2)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(N_TRAIN = 1, N_EPOCHS = 100, L_RATE = 0.0002, TRAIN_AE = False, BATCH_SIZE = 32, OUT_FILENAME = 'encoder', \n",
    "        loss_1=None, loss_2=None, encoder=None, decoder=None, device=\"cuda\", specRange=[60,900]):\n",
    "\n",
    "    trainLoader = DataLoader(\n",
    "        dataset=CustomDataset(inTrainImage,outTrainImage,specRange=specRange), \n",
    "        batch_size=32, shuffle=True\n",
    "    )\n",
    "    testLoader = DataLoader(\n",
    "        dataset=CustomDataset(inTestImage,outTestImage,specRange=specRange), \n",
    "        batch_size=1, shuffle=False\n",
    "    )\n",
    "\n",
    "    if(not loss_1): loss_1 = nn.MSELoss() # for decoder\n",
    "    if(not loss_2): loss_2 = nn.L1Loss() # addictional loss to encoder\n",
    "        \n",
    "    avg_psnr_metric = 0; total_max_psnr_metric = 0 \n",
    "    best_encoder = None\n",
    "    \n",
    "    for i_train in range(N_TRAIN):\n",
    "        \n",
    "        #if(not encoder):encoder = cEncoder(specRange[1]-specRange[0],3, CancelOut(specRange[1]-specRange[0]).to(device)).to(device)\n",
    "        if(not encoder):encoder = Encoder(specRange[1]-specRange[0],3).to(device)\n",
    "        enc_optimizer = torch.optim.Adam(encoder.parameters(), lr=L_RATE)\n",
    "        if(not decoder): decoder = Decoder(3,specRange[1]-specRange[0]).to(device)\n",
    "        dec_optimizer = torch.optim.Adam(decoder.parameters(), lr=L_RATE)\n",
    "\n",
    "        \n",
    "        ##### TRAINING #####\n",
    "        max_psnr_metric = -1\n",
    "        for epoch in range(N_EPOCHS):\n",
    "\n",
    "            for pixel , pixel_real in trainLoader:\n",
    "\n",
    "                pixel, pixel_real = pixel.to(device), pixel_real.to(device)\n",
    "                \n",
    "                ### Decoder Loss Estimation ###\n",
    "                dec_loss = 0\n",
    "                if(TRAIN_AE):\n",
    "                    dec_optimizer.zero_grad()\n",
    "                    with torch.no_grad():\n",
    "                        x1,x2,x3,x4,x5,encoded  = encoder(pixel)\n",
    "                    decoded = decoder(x1,x2,x3,x4,x5,encoded.detach())\n",
    "                    dec_loss += loss_1(decoded, pixel) \n",
    "\n",
    "                ### Encoder Loss Estimation ###\n",
    "                enc_optimizer.zero_grad()\n",
    "                x1,x2,x3,x4,x5,encoded  = encoder(pixel)\n",
    "                enc_loss = loss_2(encoded, pixel_real) \n",
    "                \n",
    "                if(TRAIN_AE): \n",
    "                    with torch.no_grad():\n",
    "                        decoded = decoder(x1,x2,x3,x4,x5,encoded)\n",
    "                    enc_loss += loss_1(decoded, pixel) \n",
    "                \n",
    "                ### Update Models Weights ###\n",
    "                enc_loss.backward()\n",
    "                enc_optimizer.step()\n",
    "                if(TRAIN_AE):\n",
    "                    dec_loss.backward()\n",
    "                    dec_optimizer.step()\n",
    "\n",
    "            ##### VALIDATING #####\n",
    "            out_img = torch.zeros(3, 31, 46)\n",
    "            for i, (pixel, pixel_real) in enumerate(testLoader):\n",
    "                pixel, pixel_real = pixel.to(device), pixel_real.to(device)\n",
    "                r = i // 46; c = i % 46\n",
    "                with torch.no_grad():\n",
    "                    x1,x2,x3,x4,x5,encoded = encoder(pixel, train=False)\n",
    "                out_img[:, r, c] = encoded\n",
    "\n",
    "            ##### SHOW CURRENT RESULTS #####    \n",
    "            psnr_metric = PSNR(out_img, outTestImage)\n",
    "            if(psnr_metric.item() > max_psnr_metric):\n",
    "                max_psnr_metric = psnr_metric.item()\n",
    "            if(psnr_metric.item() > total_max_psnr_metric):\n",
    "                best_encoder = encoder\n",
    "                save_image(out_img, './results/spec2spec/currbest_'+\n",
    "                    OUT_FILENAME+'-'\n",
    "                    'bs_'+str(BATCH_SIZE)+'-'+\n",
    "                    'lr_'+str(L_RATE)+'-'+\n",
    "                    '.png')\n",
    "            \n",
    "                \n",
    "            if(psnr_metric.item() > total_max_psnr_metric):\n",
    "                total_max_psnr_metric = psnr_metric.item()\n",
    "\n",
    "            print(\" | i_train \"+str(i_train)+ \n",
    "                \" | epoch \"+str(epoch)+\n",
    "                \" | enc_loss \"+str(round(enc_loss.item(),6))+\n",
    "                \" | psnr \"+str(round(max_psnr_metric,2)), end=\"\\r\")\n",
    "        \n",
    "        print()\n",
    "        avg_psnr_metric += max_psnr_metric / N_TRAIN\n",
    "        \n",
    "    print(\" === AVERAGE_PSNR:\"+str(round(avg_psnr_metric,2))+\" ===\")\n",
    "  \n",
    "    return best_encoder, avg_psnr_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(OUT_FILENAME = 'encoder', encoder=None, device=\"cuda\", specRange=[60,900]):\n",
    "    testLoader = DataLoader(\n",
    "        dataset=CustomDataset(inTestImage,outTestImage,specRange=specRange), \n",
    "        batch_size=1, shuffle=False\n",
    "    )\n",
    "    out_img = torch.zeros(3, 31, 46)\n",
    "    for i, (pixel, pixel_real) in enumerate(testLoader):\n",
    "        pixel, pixel_real = pixel.to(device), pixel_real.to(device)\n",
    "        r = i // 46; c = i % 46\n",
    "        with torch.no_grad():\n",
    "            x1,x2,x3,x4,x5,encoded = encoder(pixel, train=False)\n",
    "        \n",
    "        out_img[:, r, c] = encoded\n",
    "\n",
    "    ##### SHOW CURRENT RESULTS #####    \n",
    "    return out_img, PSNR(out_img, outTestImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_encoder_840_to_3, simple_encoder_840_to_3_PSNR = train(\n",
    "    N_TRAIN=1, TRAIN_AE=False, OUT_FILENAME='simple_encoder_840_to_3', loss_1=nn.MSELoss(), loss_2=nn.L1Loss(), specRange=[60,900]\n",
    ")\n",
    "\n",
    "simple_autoencoder_840_to_840, simple_autoencoder_840_to_840_PSNR = train(\n",
    "    N_TRAIN=1, TRAIN_AE=True, OUT_FILENAME='simple_autoencoder_840_to_840', loss_1=nn.MSELoss(), loss_2=nn.L1Loss(), specRange=[60,900]\n",
    ")\n",
    "\n",
    "cancelout_autoencoder_840_to_840, cancelout_autoencoder_840_to_840_PSNR = train(\n",
    "    N_TRAIN=1, TRAIN_AE=True, OUT_FILENAME='cancelout_autoencoder_840_to_840', loss_1=nn.MSELoss(), loss_2=nn.L1Loss(), specRange=[60,900],\n",
    "    encoder=cEncoder(840,3, CancelOut(840).to(device='cuda')).to(device='cuda')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_encoder_2048_to_3, simple_encoder_2048_to_3_PSNR = train(\n",
    "    N_TRAIN=1, TRAIN_AE=False, OUT_FILENAME='simple_encoder_2048_to_3', loss_1=nn.MSELoss(), loss_2=nn.L1Loss(), specRange=[0,2048]\n",
    ")\n",
    "\n",
    "simple_autoencoder_2048_to_2048, simple_autoencoder_2048_to_2048_PSNR = train(\n",
    "    N_TRAIN=1, TRAIN_AE=True, OUT_FILENAME='simple_autoencoder_2048_to_2048', loss_1=nn.MSELoss(), loss_2=nn.L1Loss(), specRange=[0,2048]\n",
    ")\n",
    "\n",
    "cancelout_autoencoder_2048_to_2048, cancelout_autoencoder_2048_to_2048_PSNR = train(\n",
    "    N_TRAIN=1, TRAIN_AE=True, OUT_FILENAME='cancelout_autoencoder_2048_to_2048', loss_1=nn.MSELoss(), loss_2=nn.L1Loss(), specRange=[0,2048],\n",
    "    encoder=cEncoder(2048,3, CancelOut(2048).to(device='cuda')).to(device='cuda')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_autoencoder_2048_to_2048, unet_autoencoder_2048_to_2048_PSNR = train(\n",
    "    N_TRAIN=1, TRAIN_AE=True, OUT_FILENAME='unet_autoencoder_2048_to_2048', loss_1=nn.MSELoss(), loss_2=nn.L1Loss(), specRange=[0,2048],\n",
    "    decoder=uDecoder(3,2048).to(device='cuda')\n",
    ")\n",
    "\n",
    "cancelout_unet_autoencoder_2048_to_2048, cancelout_unet_autoencoder_2048_to_2048_PSNR = train(\n",
    "    N_TRAIN=1, TRAIN_AE=True, OUT_FILENAME='cancelout_unet_autoencoder_2048_to_2048', loss_1=nn.MSELoss(), loss_2=nn.L1Loss(), specRange=[0,2048],\n",
    "    decoder=uDecoder(3,2048).to(device='cuda'), encoder=cEncoder(2048,3, CancelOut(2048).to(device='cuda')).to(device='cuda')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "193d8f674e04731636ced1ea9eba52f1e9e0eded6cb90b755a17d1d1364f73a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
